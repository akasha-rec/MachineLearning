지도/비지도 특성 3개 정도 뽑고 한 번 돌려보고 +a 하기

Found input variables with inconsistent numbers of samples: [112, 38]
> size가 안 맞아 > len으로 알아낼 수 없다 > 파이썬으로 해결X >> pandas로 해결해야
key(헤더) : value(데이터세트)로 가야

사이킷 런 데이터 : data(문제) - feature~ / target - target_names >> 2세트
dataFrame(data, columns=)
size가 안 맞아 1. 세트가 맞는지 확인 2. 안 맞으면 데이터 수정해야(전처리)

★ 기억
X_로 시작하는 건 문제
y_로 시작하는 건 답안지
=> X_, y_는 짝으로 같이 나와야

import로 문제가 어떻게 흘러갈 거라고 생각하고 들어가야
사이킷 런에서 주는 어떤 데이터를 쓰는구나
train_test_split 꼭 사용
근접이웃 알고리즘에 대한 거구나

선형모델 다 돼있다는 전제 > 랜덤 포레스트 먼저 > 0.64 적고 > 결정트리 > 중요 특성에 집중 > 랜덤 포레스트 한 번 더 >
선형 모델로 0.67 나왔다 > SVM 
베이스라인을 긋고 확인> 결정트리 > 랜덤 포레스트 > feature 값 잡고
★ 결정 트리 : 분류, 회귀모델 보다는 중요 특성을 파악할 때(질문을 통한 답변) > 데이터 분석(한정된 시간, 많은 데이터)
복잡도 제어가 제일 중요(깊이가 깊어질수록 overfit됨 > 해결X, 대안으로는 매개변수 조정)
데이터 민감도가 엄청 높아

단독 모델 overfitting에 집중 > 모델을 합쳐볼까? 선형 | 비선형 | 결정트리 각각 학습시켜 + 투표 => 앙상블?
모든 알고리즘은 overfit이 default.

stratify=cancer.target 의미
- 분류가 일정하지 않을 때 계층 분류를 써서 좀 더 세밀하고 균등하게 분류

True면 왼쪽으로 / False면 오른쪽으로

결정트리 먼저 해보고 다음에
랜덤 포레스트 > 분류 회귀 모두에서 많이 써 > 처음부터 적용하기 좋은 알고리즘 + 설명력이 좋아
단일 앙상블 모델(결정트리만 학습시켜) + p122 부트스트랩 샘플
- 민감도 제어O
- 전처리 하지 않아도 돼 > 사랑받는 이유
- 계산량 폭증, 속도가 느려

SVM : 분류 회귀 모두에서 많이 써(양쪽 모두에서 균등한 성능) > "데이터가 얼마 없음" > 효용가치 ↑(수학자들이 만든)
- 수렴을 보장

머신러닝은 블랙박스 모델 : 입력값을 넣어서 출력값이 나오는데 왜 나오는지 몰라

★ 수형도 그릴 줄 알아야
★ 박스 값 이해?

딥러닝 전제
- 발산X
- 기울기 소실X
